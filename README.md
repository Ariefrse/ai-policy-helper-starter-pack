<video src="ai-policy-helper-demo-title.mp4" controls width="600">
  
</video>

# AI Policy & Product Helper

A local-first RAG starter with **FastAPI** (backend), **Next.js** (frontend), and **Qdrant** (vector DB). Runs with one command using Docker Compose.


## Quick start

1) **Copy `.env.example` â†’ `.env`** and edit as needed.

2) **Run everything**:
```bash
docker compose up --build
```
- Frontend: http://localhost:3000  
- If port 3000 is busy, set `FRONTEND_PORT` in `.env` (e.g., `FRONTEND_PORT=3001`) and access `http://localhost:3001`.
- Backend:  http://localhost:8000/docs  
- Qdrant:   http://localhost:6333 (UI)
 

3) **Ingest sample docs** (from the UI Admin tab) or:
```bash
curl -X POST http://localhost:8000/api/ingest
```

4) **Ask a question**:
```bash
curl -X POST http://localhost:8000/api/ask -H 'Content-Type: application/json' \
  -d '{"query":"Whatâ€™s the shipping SLA to East Malaysia for bulky items?"}'
```

## Offline-friendly
- If you **donâ€™t** set an API key, the backend uses a **deterministic stub LLM** and a **built-in embedding** to keep everything fully local.
- If you set `OPENAI_API_KEY` (or configure Ollama), the backend will use real models automatically.

## Project layout
```
ai-policy-helper/
â”œâ”€ backend/
â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ main.py                 # FastAPI app + endpoints (with deduplication & categorization)
â”‚  â”‚  â”œâ”€ settings.py             # config/env
â”‚  â”‚  â”œâ”€ orchestrator.py         # RAG engine orchestrator with metrics & service health
â”‚  â”‚  â”œâ”€ embeddings.py           # Local embedding implementation (deterministic hashing)
â”‚  â”‚  â”œâ”€ vector_store.py         # Qdrant + InMemory store with fallback
â”‚  â”‚  â”œâ”€ llm_providers.py        # OpenAI + Stub LLM with deduplication logic
â”‚  â”‚  â”œâ”€ ingest.py               # doc loader & chunker
â”‚  â”‚  â”œâ”€ utils.py                # Utility functions (retry logic, etc.)
â”‚  â”‚  â”œâ”€ rag.py                  # Backward compatibility wrapper
â”‚  â”‚  â”œâ”€ models.py               # pydantic models
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â””â”€ tests/
â”‚  â”‚     â”œâ”€ conftest.py
â”‚  â”‚     â”œâ”€ test_api.py           # API endpoint tests
â”‚  â”‚     â”œâ”€ test_acceptance.py    # Acceptance criteria tests
â”‚  â”‚     â””â”€ test_end_to_end.py   # End-to-end integration tests
â”‚  â”œâ”€ requirements.txt
â”‚  â””â”€ Dockerfile
â”œâ”€ frontend/
â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ page.tsx                # chat UI
â”‚  â”‚  â”œâ”€ layout.tsx
â”‚  â”‚  â””â”€ globals.css
â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ Chat.tsx                # Enhanced chat with deduplication & categorization display
â”‚  â”‚  â””â”€ AdminPanel.tsx          # Admin panel for ingestion & metrics
â”‚  â”œâ”€ lib/api.ts                 # API client
â”‚  â”œâ”€ package.json
â”‚  â”œâ”€ tsconfig.json
â”‚  â”œâ”€ next.config.js
â”‚  â”œâ”€ next-env.d.ts              # Next.js type definitions
â”‚  â””â”€ Dockerfile
â”œâ”€ data/                         # sample policy docs
â”‚  â”œâ”€ Compliance_Notes.md
â”‚  â”œâ”€ Delivery_and_Shipping.md
â”‚  â”œâ”€ Internal_SOP_Agent_Guide.md
â”‚  â”œâ”€ Product_Catalog.md
â”‚  â”œâ”€ Returns_and_Refunds.md
â”‚  â””â”€ Warranty_Policy.md
â”œâ”€ docs/                         # Additional documentation
â”‚  â”œâ”€ DEVELOPER_GUIDE.md         # Developer setup guide
â”‚  â”œâ”€ DEPLOYMENT.md              # Production deployment guide
â”‚  â””â”€ API_PLAYGROUND.md          # Interactive API testing
â”œâ”€ docker-compose.yml            # Removed obsolete version attribute
â”œâ”€ Makefile
â”œâ”€ .env.example
â””â”€â”€ .gitignore                    # Proper gitignore for security
```

## Tests
Run all tests inside the backend container:
```bash
docker compose run --rm -v ./data:/app/data:ro backend pytest -q
```

**Test Coverage:**
- **Unit tests**: API endpoints, models validation (3 tests)
- **Integration tests**: End-to-end RAG pipeline, citation accuracy, performance benchmarks (4 tests)
- **Acceptance tests**: Acceptance criteria validation (2 tests)
- **Total**: 9 tests covering functionality, performance, and error handling

Run specific test suites:
```bash
# API and unit tests only
docker compose run --rm -v ./data:/app/data:ro backend pytest app/tests/test_api.py -v

# End-to-end integration tests
docker compose run --rm -v ./data:/app/data:ro backend pytest app/tests/test_end_to_end.py -v

# Acceptance criteria tests
docker compose run --rm -v ./data:/app/data:ro backend pytest app/tests/test_acceptance.py -v
```

## Performance Benchmarks

**System Performance (measured on local development):**
- **Retrieval Latency**: ~12ms average (local embeddings)
- **Generation Latency**: ~2.7s average (OpenAI gpt-4o-mini API)  
- **Memory Usage**: Bounded at 1000 retrieval + 500 generation cache entries
- **Throughput**: Handles concurrent requests with thread-safe operations
- **Cache Hit Rates**: Improves performance for repeated queries

**Production Considerations Implemented:**
- ğŸ”’ **Security**: Input validation (1-1000 chars), API key protection, environment-specific CORS
- ğŸš€ **Performance**: LRU caching with bounded memory, deterministic local embeddings
- ğŸ” **Observability**: Structured logging, comprehensive metrics collection, health endpoints
- ğŸ›¡ï¸ **Reliability**: Error handling with LLM fallbacks, thread-safe vector operations, graceful degradation

## Notes
- Keep it simple. For take-home, focus on correctness, citations, and clean code.

## Architecture (ASCII)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP/3001    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Browser  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚    Next.js Frontend  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â”Œâ”€ Chat Component    â”‚
                                    â”‚  â””â”€ Admin Panel      â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚ fetch /api/*
                                               â–¼ HTTP/8000
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Backend                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Input Validationâ”‚   â”‚  Error Handling â”‚   â”‚  CORS Config  â”‚  â”‚
â”‚  â”‚  â”œâ”€ Pydantic     â”‚   â”‚  â”œâ”€ Structured  â”‚   â”‚  â”œâ”€ Dev: local â”‚  â”‚
â”‚  â”‚  â”œâ”€ XSS Filter   â”‚   â”‚  â”‚   Logging    â”‚   â”‚  â””â”€ Prod: env â”‚  â”‚
â”‚  â”‚  â””â”€ Length Limit â”‚   â”‚  â””â”€ Fallbacks   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    RAG Engine                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚   Ingest     â”‚ â”‚  Retrieve   â”‚ â”‚      Generate        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â”œâ”€ Load /data â”‚ â”‚ â”œâ”€ Embed Q  â”‚ â”‚ â”œâ”€ OpenAI/Stub LLM  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â”œâ”€ Chunk docs â”‚ â”‚ â”œâ”€ Search   â”‚ â”‚ â”œâ”€ Context prompt   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚ â””â”€ Thread-safeâ”‚ â”‚ â”œâ”€ MMR rank â”‚ â”‚ â”œâ”€ PII masking     â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€ LRU cache â”‚ â”‚ â””â”€ LRU cache       â”‚  â”‚ â”‚
â”‚  â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼ upsert/search
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Qdrant Vector DB             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Collections   â”‚ â”‚    Persistence  â”‚ â”‚
â”‚  â”‚ â”œâ”€ policy_helperâ”‚ â”‚ â”œâ”€ Docker Vol   â”‚ â”‚
â”‚  â”‚ â””â”€ 384-dim vecs â”‚ â”‚ â””â”€ Health check â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–² fallback to in-memory if unavailable
```

---

## Candidate Instructions (Read Me First)

### Goal
Build a local-first **Policy & Product Helper** using RAG that:
- Ingests the sample docs under `/data`
- Answers questions with **citations** (title + section)
- Exposes metrics and health endpoints
- Provides a minimal **chat UI** and **admin panel**

You have **48 hours** once you start. AI coding tools are allowed.

### Deliverables
1. **GitHub repo link** with your changes.
2. **README** describing setup, architecture, trade-offs, and what youâ€™d ship next.
3. **2â€“5 minute screen capture** demonstrating ingestion + Q&A + citations.
4. **Tests**: show how to run them and their results (e.g., `pytest -q`).

### Acceptance Checks (we will run)
1. `docker compose up --build` boots **Qdrant + backend + frontend**.
2. Use Admin tab to **ingest** docs without errors.
3. Ask: *â€œCan a customer return a damaged blender after 20 days?â€* â†’ cites **Returns_and_Refunds.md** and **Warranty_Policy.md**.
4. Ask: *â€œWhatâ€™s the shipping SLA to East Malaysia for bulky items?â€* â†’ cites **Delivery_and_Shipping.md** (mentions bulky item surcharge).
5. Expand a citation chip and see the underlying chunk text.

### Rubric (100 pts)
- **Functionality & correctness (35)** â€” ingestion, RAG with citations, metrics, health.
- **Code quality & structure (20)** â€” small functions, separation of concerns, typing, linting.
- **Reproducibility & docs (15)** â€” clear README, env.example, diagrams.
- **UX & DX polish (10)** â€” responsive, accessible, solid loading/errors.
- **Testing (10)** â€” meaningful unit/integration tests that run locally.
- **Performance & observability (10)** â€” reasonable latency, useful metrics/logs.

### How to Run (Docker)
```bash
# copy env
cp .env.example .env

# run all services
docker compose up --build

# endpoints
# frontend: http://localhost:3000
# backend swagger: http://localhost:8000/docs
# qdrant ui: http://localhost:6333
 
```

### How to Run (No Docker, optional)
Backend:
```bash
python -m venv .venv && source .venv/bin/activate
pip install -r backend/requirements.txt
uvicorn app.main:app --host 0.0.0.0 --port 8000 --app-dir backend
```
Frontend:
```bash
cd frontend
npm install
npm run dev
# open http://localhost:3000
```

### Switching LLMs
- Default is **stub** (deterministic, offline).
- To use OpenAI: set `LLM_PROVIDER=openai` and `OPENAI_API_KEY` in `.env`. (You are required to demo with OpenAI, API key is provided)
- To use Ollama: set `LLM_PROVIDER=stub` (keep stub) or extend `rag.py` to add an `OllamaLLM` class.
- Please document any changes you make.

### Vector Store
- Default is **Qdrant** via Docker. Fallback is in-memory if Qdrant isnâ€™t available.
- To switch to in-memory explicitly: `VECTOR_STORE=memory` in `.env`.

### API Reference
- `POST /api/ingest` â†’ `{ indexed_docs, indexed_chunks }`
- `POST /api/ask` body:
  ```json
  { "query": "What's the refund window for Category A?", "k": 4 }
  ```
  Response includes `answer`, `citations[]`, `chunks[]`, `metrics`.
- `GET /api/metrics` â†’ counters + avg latencies
- `GET /api/health` â†’ `{ "status": "ok" }`

### UI Walkthrough
1. Open **http://localhost:3000**.
2. In **Admin** card, click **Ingest sample docs** and then **Refresh metrics**.
3. In **Chat**, ask questions. Click the **source badges** to expand supporting chunks.

### What You Can Modify
- Anything. Improve chunking, reranking (MMR), prompt, UI polish, streaming, caching, guardrails (PDPA masking), feedback logging, small eval script, etc.
- Keep the one-command run and README accurate.

### Constraints & Notes
- Keep keys out of the frontend.
- Validate file types if you extend ingestion to uploads.
- Provide small architecture diagram if you can (ASCII is fine).

### Troubleshooting
- **Qdrant healthcheck failing**: ensure port `6333` is free; re-run compose.
 
- **CORS errors**: 
  - Development: allows localhost:3000, localhost:3001, 127.0.0.1:3000, 127.0.0.1:3001
  - Production: set `ALLOWED_ORIGINS` env var (comma-separated URLs)
  - Environment detection: set `ENVIRONMENT=production` for prod CORS rules
- **Frontend port conflicts**: set `FRONTEND_PORT` in `.env` if 3000 is busy
- **Embeddings/LLM**: With no keys, stub models run by default so the app always works.
- **Input validation errors**: queries are limited to 1000 chars, XSS patterns blocked
- **Memory issues**: caches are bounded (1000 retrieval, 500 generation entries)

---

## Implementation Notes

### Security & Quality Improvements Made

**Critical Security Fixes:**
- âœ… **Removed API key exposure** - `.env` file removed from git, proper `.gitignore` added
- âœ… **Input validation** - Pydantic validators with length limits (1-1000 chars), XSS pattern detection
- âœ… **CORS security** - Environment-specific origins instead of wildcard `*`

**Code Quality Enhancements:**
- âœ… **Error handling** - Structured logging with fallback mechanisms for LLM failures
- âœ… **Thread safety** - Locks for concurrent ingestion operations to prevent race conditions
- âœ… **Memory management** - LRU caches (1000 retrieval, 500 generation) to prevent unbounded growth
- âœ… **Observability** - Detailed logging for debugging and monitoring

### Trade-offs & Design Decisions

**Performance vs Security:**
- Input validation adds ~1-2ms latency but prevents injection attacks
- Thread locks reduce concurrency but ensure data consistency
- Cache size limits prevent memory leaks but may increase miss rates

**Complexity vs Maintainability:**
- Added structured logging increases code size but improves debugging
- LRU cache implementation adds complexity but essential for production
- Environment-based CORS adds configuration but improves security

**Development vs Production:**
- Stub LLM fallback ensures offline development works
- Different CORS policies for dev vs prod environments
- Deterministic embeddings for reproducible testing

### Next Steps for Production

**Short-term (next sprint):**
1. **Authentication & authorization** - Add user sessions and API keys
2. **Rate limiting** - Prevent abuse with request throttling  
3. **Monitoring** - Add Prometheus metrics and health checks
4. **Error recovery** - Implement circuit breakers for external APIs

**Medium-term (next quarter):**
1. **Streaming responses** - Real-time answer generation for better UX
2. **Advanced retrieval** - Hybrid search (semantic + keyword)
3. **Document versioning** - Track changes to policy documents
4. **A/B testing** - Experiment with different prompt strategies

**Long-term (roadmap):**
1. **Multi-tenant support** - Separate document collections per organization
2. **Advanced analytics** - Usage patterns and query analysis
3. **AI-powered summaries** - Automatic policy change summaries
4. **Integration APIs** - Connect with external systems (Slack, Teams)

### Submission
- Share GitHub repo link + your short demo video.
- Include any notes on trade-offs and next steps.

## Deployment Guide
See `docs/DEPLOYMENT.md` for production setup: env vars, CORS, OpenAI/Ollama, scaling, monitoring, and troubleshooting.
