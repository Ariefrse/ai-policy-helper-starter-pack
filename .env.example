# Backend Configuration
EMBEDDING_MODEL=local-384
LLM_PROVIDER=stub           # options: stub | openai | ollama
OPENAI_API_KEY=             # REQUIRED for demo: set your OpenAI API key here
OLLAMA_HOST=http://ollama:11434
VECTOR_STORE=qdrant         # qdrant | memory
COLLECTION_NAME=policy_helper
CHUNK_SIZE=700
CHUNK_OVERLAP=80

# Security & CORS Settings
ENVIRONMENT=development     # development | production
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001  # for production
MASK_PII=true              # enable PII masking (emails, ICs, long numbers)

# Frontend
NEXT_PUBLIC_API_BASE=http://localhost:8000
FRONTEND_PORT=3000
